{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21a2319",
   "metadata": {},
   "source": [
    "# WORKSHOP 2\n",
    "\n",
    "------------\n",
    "\n",
    "**<u>GRUPO 4<u>**\n",
    "\n",
    "Digital House\n",
    "\n",
    "link git hub: https://github.com/grupo4dhds/grupo4_git.git\n",
    "\n",
    "--------------\n",
    "## ACLARACIONES\n",
    "\n",
    "**Cambio en la convensión de Dicto[keys], a partir de ahora la posición [0] (*) se utiliza para el dicionario main y el resto de indices para datas auxiliares**\n",
    "    \n",
    "**Creacion de Dicture = {}: no tiene filtro, todos los modelos que se entren para uso general o uso predictorio tienen que aparecer dentro de este set**\n",
    "    \n",
    "**Creacion de Model = {}: este diccionario contiene unicamente los modelos predictorios**\n",
    "    \n",
    "**Dicto['models']: no es para analizar dicho modelo, sino para comparar los features y los parámetros estimados ENTRE modelos, para analisis del modelo dirigirse a Dicture**\n",
    "    \n",
    "**Dicto['models']: caso excepcional con posición única (*)**\n",
    "    \n",
    "    \n",
    "## ACLARACIONES 2\n",
    "    \n",
    "**Dicto almacena diccionarios de dataframes, la llave models tiene la expeción de tener una posicion/etiquéta unica, por lo tanto se almacena en formato tipo DataFrame**\n",
    "    \n",
    "**Dicture: almacena 3 dataframes, y 2 arrays por matriz feature creada; por convención al crearse una llave todas las posiciones de la tupla deben completarse, para aquellas que no estén, no existan ni vayan a existir se designa con 0, y aquellas que vayan a estar se designa 1**\n",
    "\n",
    "**Model: Solo aquellos modelos entrenados, que hayan pasado por la instancia 5, fit, entran en esta categoría, revisar disparidades con Dicture**\n",
    "    \n",
    "**Dicture: La principal diferencia entre una llave Dicture que se encuentra dentro de Model y una que no, es que Dicture en Model incluye valores de performance (* *), y Dicture que no esté en model un string con los hiperparámetros de la instanciacion**\n",
    "    \n",
    "**Dicture: identificar los performance (* *) que son en string como valores representativos del modelo, y los que están en otro tipo de variable son porque tiene utilidad como hiperparámetro de otro modelo**    \n",
    "    \n",
    "**Dicture: la longitud de la tupla puede variar en funcion de las performance que se convierten en hiperparámetros de las que no**    \n",
    "    \n",
    "## CONTENIDO\n",
    "    \n",
    "    **IMPORTANTE: frenarse en las celda 28 para explicar un poco la estructura de datos**\n",
    "\n",
    "After cell 12:\n",
    "    \n",
    "    Dicto.keys(): (actualizar)\n",
    "        - data_cruda\n",
    "        - surface_nan\n",
    "        - data\n",
    "        - dummy_place\n",
    "\n",
    "Celda 12:\n",
    "    \n",
    "    * implementación del modelo machine learning\n",
    "\n",
    "Celda 12-13:    \n",
    "    \n",
    "    * creacion Dicture[linreg] = X, y, linreg.intercept_, linreg.coef_, y_pred_train\n",
    "    * creacion: Dicto[models] = data_models \n",
    "    * creacion Model[linreg] = linreg, Dicto[models], Dicture[linreg]\n",
    "\n",
    "(DESACTUALIZACION INDICE CELDAS)    \n",
    "\n",
    "Celda 18:\n",
    "    \n",
    "    * prediccion del modelo sobre una muestra de datos extraídos de otra sección del dataset original\n",
    "    \n",
    "Celda 19: (mask_2 ask)\n",
    "    \n",
    "    * Chequeo de cuanto afecta considerar las labels categorizadas como \"otros\"\n",
    "\n",
    "##Celda 21:\n",
    "    \n",
    "    * Recordar que esta muestra viene de otro criterio de seleccion, y por eso es necesario matchiar valores estadísticos que se calcularon sin ser estos elementos parte de la muestra\n",
    "\n",
    "Celda 25:    \n",
    "    \n",
    "    * Guardado de la data: Dicto['muestra']\n",
    "    \n",
    "Celda 27:\n",
    "    \n",
    "    * Comprobación visual del rango de aplicacion del modelo: (aclaracion en parte 2 - After regularizacón)\n",
    "    \n",
    "Celda 29: \n",
    "    \n",
    "    * Chequear esa celda que trabaja con un data_aux, no entiendo la complicación de empalme que podría estar sucediendo\n",
    "    \n",
    "Celda 31: \n",
    "    \n",
    "    * grafico - visualizacion\n",
    "    \n",
    "... continua con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91ea413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6db00a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07afcbf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def lista_featurend(X, label_i):\n",
    "    for i in range(len(X.columns)):\n",
    "        if list(X.columns)[i] == label_i:\n",
    "            lista_featur_end = (list(X.columns)[i:])\n",
    "    return lista_featur_end\n",
    "        \n",
    "def cambia_nombre_columnas(data, **kwarg):\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "    for key in kwarg.keys():\n",
    "        data.rename(kwarg[key], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def cambia_orden_columnas(check_list, data, safe=1): # safe: es para conservar la primera columna con indice[0]\n",
    "    label_list = list(data.columns)\n",
    "    for i in range(len(check_list)):\n",
    "        label_list.remove(check_list[i])\n",
    "        label_list.insert(i+safe, check_list[i])\n",
    "        data = data.reindex(label_list, axis=1)\n",
    "        \n",
    "def data_info(data, name='data'):\n",
    "    df = pd.DataFrame(pd.Series(data.columns))\n",
    "    df.columns = ['columna']\n",
    "    df.columns.name = f'df de {name}'\n",
    "    df.index.name = 'index'\n",
    "    df['Nan'] = data.isna().sum().values\n",
    "    df['dtype']  = data.dtypes.values\n",
    "    df['count'] = data.count().values\n",
    "    df['pct_nan'] = round(df['Nan']/data.shape[0]*100,2)\n",
    "    df['count_unique'] = [len(data[elemento].value_counts()) for elemento in data.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualizacion_dos_scatter(frame1, frame2, x, y_1, y_2):\n",
    "    x1 = frame1[x]\n",
    "    x2 = frame2[x]\n",
    "    y_real = frame1[y_1]\n",
    "    y_pred = frame2[y_2]\n",
    "    plt.scatter(x1, y_real)\n",
    "    plt.scatter(x2, y_pred) # muestra, entonces com\n",
    "    plt.suptitle('y, y_pred');\n",
    "    \n",
    "    \n",
    "    ax = plt.axes() #instancia de un objeto\n",
    "    # tiene atributos y tiene métodos\n",
    "    # los atributos .algo y los métodos son .algo()\n",
    "    # \n",
    "    ax.set(xlabel = 'x', ylabel='price')\n",
    "    #azules reales\n",
    "    #naranjas predichos\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "dame dos datasets, ya filtrados\n",
    "\n",
    "# separame el eje x, de cualquier de los dos datasets\n",
    "# armame una serie de cada valor real/predicho\n",
    "\"\"\";\n",
    "def variables_feature(frame):\n",
    "    frame['sup_total_pow2'] = frame.surface_total_in_m2 * frame.surface_total_in_m2\n",
    "    frame['sup_descubierta'] = frame.surface_total_in_m2 - frame.surface_covered_in_m2\n",
    "    frame['sup_descubierta_pct'] = frame.sup_descubierta / frame.surface_total_in_m2 *100\n",
    "    frame = frame.drop('sup_descubierta', axis=1)\n",
    "    return frame\n",
    "\n",
    "def analisis_nans(frame):\n",
    "    df = data_info(frame)\n",
    "    lista_not_na = list((df[df.Nan == 0].columna).values)\n",
    "    lista_con_na = list((df[df.Nan != 0].columna).values)\n",
    "    \n",
    "    print ('ANALISIS DE NANS')\n",
    "    print (frame[lista_con_na].isna().sum().to_string())\n",
    "    #print ('La suma es {}'.format(3198+746))\n",
    "    print ('Cantidad de elemento: {}'.format(frame[lista_con_na].shape[0]))\n",
    "    print ('Interseccion entre los nan encuentra: {} elementos'.format(frame[lista_con_na].isna().all(axis=1).sum()))\n",
    "    print('Union entre los nan encuentra: {} elementos'.format(frame[lista_con_na].isna().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27eb6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['property_type', 'place_name', 'state_name', 'price', 'currency', 'surface_total_in_m2', 'surface_covered_in_m2', 'price_usd_per_m2', 'place_name_2']\n",
      "['above_mean', 'above_median']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_apartment_5_final.csv')\n",
    "data.drop(list(data.columns)[0], axis=1, inplace=True)\n",
    "lista_columnas_1 = list(data.columns)[:9]\n",
    "lista_columnas_2 = lista_featurend(data,'above_mean')\n",
    "print(lista_columnas_1)\n",
    "print(lista_columnas_2)\n",
    "data = data.loc[:,lista_columnas_1 + lista_columnas_2]\n",
    "\n",
    "Dicto = {}\n",
    "Dicture = {}\n",
    "Model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77a9f675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>df de data</th>\n",
       "      <th>columna</th>\n",
       "      <th>Nan</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>pct_nan</th>\n",
       "      <th>count_unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>property_type</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place_name</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>state_name</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currency</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surface_total_in_m2</td>\n",
       "      <td>3198</td>\n",
       "      <td>float64</td>\n",
       "      <td>12744</td>\n",
       "      <td>20.06</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surface_covered_in_m2</td>\n",
       "      <td>746</td>\n",
       "      <td>float64</td>\n",
       "      <td>15196</td>\n",
       "      <td>4.68</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price_usd_per_m2</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>place_name_2</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_median</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>15942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "df de data                columna   Nan    dtype  count  pct_nan  count_unique\n",
       "index                                                                         \n",
       "0                   property_type     0   object  15942     0.00             1\n",
       "1                      place_name     0   object  15942     0.00           113\n",
       "2                      state_name     0   object  15942     0.00             5\n",
       "3                           price     0  float64  15942     0.00          2671\n",
       "4                        currency     0   object  15942     0.00             1\n",
       "5             surface_total_in_m2  3198  float64  12744    20.06           168\n",
       "6           surface_covered_in_m2   746  float64  15196     4.68           191\n",
       "7                price_usd_per_m2     0  float64  15942     0.00          6332\n",
       "8                    place_name_2     0   object  15942     0.00            51\n",
       "9                      above_mean     0  float64  15942     0.00             2\n",
       "10                   above_median     0  float64  15942     0.00             2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_info(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7cebd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_not_na = list((df[df.Nan == 0].columna).values)\n",
    "lista_con_na = list((df[df.Nan != 0].columna).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "644b9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISIS DE NANS\n",
      "surface_total_in_m2      3198\n",
      "surface_covered_in_m2     746\n",
      "La suma es 3944\n",
      "Cantidad de elemento: 15942\n",
      "Interseccion entre los nan encuentra: 0 elementos\n",
      "Union entre los nan encuentra: 3944 elementos\n",
      "\n",
      "Se toma muestra de los valores y se los quita del dataset\n"
     ]
    }
   ],
   "source": [
    "print ('ANALISIS DE NANS')\n",
    "print (data[lista_con_na].isna().sum().to_string())\n",
    "print ('La suma es {}'.format(3198+746))\n",
    "print ('Cantidad de elemento: {}'.format(data[lista_con_na].shape[0]))\n",
    "\n",
    "print ('Interseccion entre los nan encuentra: {} elementos'.format(data[lista_con_na].isna().all(axis=1).sum()))\n",
    "print('Union entre los nan encuentra: {} elementos'.format(data[lista_con_na].isna().any(axis=1).sum()))\n",
    "\n",
    "print ('\\nSe toma muestra de los valores y se los quita del dataset')\n",
    "\n",
    "muestra = data[data[lista_con_na].isna().any(axis=1)]\n",
    "df = data_info(muestra, 'surface_nan')\n",
    "data = data.drop(muestra.index)\n",
    "\n",
    "Dicto['data_cruda'] = data.to_dict(), data_info(data).to_dict() # data cruda sin nans\n",
    "Dicto['surface_nan'] = muestra.to_dict(), df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38483e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicto['data'] = data.to_dict(), data_info(data).to_dict()\n",
    "Dicto['data_pred'] = data.to_dict(), data_info(data).to_dict() # conservo columnas innecesarias pero cómodas a la vista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e08f4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = variables_feature(data)\n",
    "\n",
    "dummy_place = pd.get_dummies(data['place_name_2'])\n",
    "df = data_info(dummy_place)['columna']\n",
    "\n",
    "place_name_2 = data.place_name_2\n",
    "data = data.drop('place_name_2', axis=1)\n",
    "\n",
    "Dicto['data'] = data.to_dict(), data_info(data).to_dict() #sin columnas innecesarias y con las columnas agregadas\n",
    "Dicto['dummy_place'] = dummy_place.to_dict(), df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe0b037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>place_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>above_mean</th>\n",
       "      <th>above_median</th>\n",
       "      <th>sup_total_pow2</th>\n",
       "      <th>sup_descubierta_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>72000.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1309.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>67000.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1675.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>90000.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1730.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>7.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>88000.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>50.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1760.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>93600.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>9.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Merlo</td>\n",
       "      <td>Bs.As. G.B.A. Zona Oeste</td>\n",
       "      <td>63759.245132</td>\n",
       "      <td>USD</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1752.614722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Merlo</td>\n",
       "      <td>Bs.As. G.B.A. Zona Oeste</td>\n",
       "      <td>63759.245132</td>\n",
       "      <td>USD</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1752.614722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15939</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Merlo</td>\n",
       "      <td>Bs.As. G.B.A. Zona Oeste</td>\n",
       "      <td>52140.893797</td>\n",
       "      <td>USD</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1719.899333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15940</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Merlo</td>\n",
       "      <td>Bs.As. G.B.A. Zona Oeste</td>\n",
       "      <td>58375.131099</td>\n",
       "      <td>USD</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1699.005294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15941</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Merlo</td>\n",
       "      <td>Bs.As. G.B.A. Zona Oeste</td>\n",
       "      <td>148000.000000</td>\n",
       "      <td>USD</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1973.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11998 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_type place_name                state_name          price  \\\n",
       "0         apartment  Mataderos           Capital Federal   72000.000000   \n",
       "1         apartment  Mataderos           Capital Federal   67000.000000   \n",
       "2         apartment  Mataderos           Capital Federal   90000.000000   \n",
       "3         apartment  Mataderos           Capital Federal   88000.000000   \n",
       "4         apartment  Mataderos           Capital Federal   93600.000000   \n",
       "...             ...        ...                       ...            ...   \n",
       "15937     apartment      Merlo  Bs.As. G.B.A. Zona Oeste   63759.245132   \n",
       "15938     apartment      Merlo  Bs.As. G.B.A. Zona Oeste   63759.245132   \n",
       "15939     apartment      Merlo  Bs.As. G.B.A. Zona Oeste   52140.893797   \n",
       "15940     apartment      Merlo  Bs.As. G.B.A. Zona Oeste   58375.131099   \n",
       "15941     apartment      Merlo  Bs.As. G.B.A. Zona Oeste  148000.000000   \n",
       "\n",
       "      currency  surface_total_in_m2  surface_covered_in_m2  price_usd_per_m2  \\\n",
       "0          USD                 55.0                   55.0       1309.090909   \n",
       "1          USD                 40.0                   28.0       1675.000000   \n",
       "2          USD                 52.0                   48.0       1730.769231   \n",
       "3          USD                 50.0                   38.0       1760.000000   \n",
       "4          USD                 51.0                   46.0       1835.294118   \n",
       "...        ...                  ...                    ...               ...   \n",
       "15937      USD                 36.0                   33.0       1752.614722   \n",
       "15938      USD                 36.0                   33.0       1752.614722   \n",
       "15939      USD                 30.0                   28.0       1719.899333   \n",
       "15940      USD                 34.0                   32.0       1699.005294   \n",
       "15941      USD                 75.0                   75.0       1973.333333   \n",
       "\n",
       "       above_mean  above_median  sup_total_pow2  sup_descubierta_pct  \n",
       "0             0.0           1.0          3025.0             0.000000  \n",
       "1             0.0           0.0          1600.0            30.000000  \n",
       "2             0.0           1.0          2704.0             7.692308  \n",
       "3             0.0           0.0          2500.0            24.000000  \n",
       "4             0.0           0.0          2601.0             9.803922  \n",
       "...           ...           ...             ...                  ...  \n",
       "15937         0.0           1.0          1296.0             8.333333  \n",
       "15938         0.0           1.0          1296.0             8.333333  \n",
       "15939         0.0           0.0           900.0             6.666667  \n",
       "15940         0.0           0.0          1156.0             5.882353  \n",
       "15941         1.0           1.0          5625.0             0.000000  \n",
       "\n",
       "[11998 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8a4437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             property_type\n",
      "1                place_name\n",
      "2                state_name\n",
      "3                     price\n",
      "4                  currency\n",
      "5       surface_total_in_m2\n",
      "6     surface_covered_in_m2\n",
      "7          price_usd_per_m2\n",
      "8                above_mean\n",
      "9              above_median\n",
      "10           sup_total_pow2\n",
      "11      sup_descubierta_pct\n"
     ]
    }
   ],
   "source": [
    "# modulo de visualizacion de columnas\n",
    "print (pd.Series(data.columns).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0fc382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 26221.099962067852\n",
      "MSE: 1309469393.2819934\n",
      "RMSE: 36186.591346547044\n",
      "R2: 0.8298430396074956\n"
     ]
    }
   ],
   "source": [
    "## Celda 12: contenido\n",
    "# 1. Seleccion de la clase de modelo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. Elegir los hiperparámetros del modelo\n",
    "linreg = LinearRegression(normalize=True) # False: default but then change to True and see changes\n",
    "\n",
    "#3. Preparar los datos en una matriz de features, y un vector target\n",
    "\n",
    "features_1 = ['surface_total_in_m2', 'sup_total_pow2', 'sup_descubierta_pct', 'above_mean']\n",
    "features_2 = ['surface_total_in_m2', 'sup_total_pow2', 'sup_descubierta_pct', 'above_median']\n",
    "\n",
    "\n",
    "X = pd.concat([data[features_1],dummy_place], axis=1)\n",
    "\n",
    "\n",
    "y = data.price\n",
    "y = y[y.index.intersection(X.index)]\n",
    "\n",
    "#4. Separar los sets de entrenamiento y de testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)\n",
    "\n",
    "#5. Ajustar el modelo a los datos de entrenamiento\n",
    "linreg.fit(Xtrain, ytrain)\n",
    "\n",
    "#6. Predecir etiquetas para datos desconocidos\n",
    "y_pred = linreg.predict(Xtest)\n",
    "\n",
    "#7. Evaluar la perfomance del modelo\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print ('MAE:', metrics.mean_absolute_error(ytest, y_pred))\n",
    "print ('MSE:', metrics.mean_squared_error(ytest, y_pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, y_pred)))\n",
    "print ('R2:', metrics.r2_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda910e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c2ed711",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 13\n",
    "y_pred_train = linreg.predict(Xtrain)\n",
    "Dicture['linreg'] = X, pd.DataFrame(y), pd.DataFrame({'B_0': {'linreg': linreg.intercept_}}), linreg.coef_, y_pred_train, 'MAE: 26221.099962067852, MSE: 1309469393.2819934, RMSE: 36186.591346547044, R2: 0.8298430396074956'\n",
    "\n",
    "lista_features = list(X.columns)\n",
    "B_0 = linreg.intercept_\n",
    "\n",
    "data_models = pd.DataFrame({'B_0': {'linreg': B_0}})\n",
    "\n",
    "dicc = {}\n",
    "for i in range(len(lista_features)):\n",
    "    dicc[lista_features[i]] = {'linreg': linreg.coef_[i]}\n",
    "    \n",
    "Dicto['models'] = data_models.join(pd.DataFrame(dicc))\n",
    "\n",
    "Model['linreg'] = linreg, Dicto['models'], Dicture['linreg'] #marca la pauta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e11dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels as sm # error\n",
    "#help(LinearRegression)\n",
    "#help(LinearRegression.predict)\n",
    "#help(sm.fittedvalues) # no logro hacerlo funcionar proviene de la notebook de dani\n",
    "\"\"\"\n",
    "    VALORES CON valor=84, valor: cantidad de publicaciones minimas para conservar place_name (proviene de notebook G4_main)\n",
    "Normalize: False (no varía si se cambia a True)\n",
    "MAE: 26388.597029743163\n",
    "MSE: 1290767140.9256575\n",
    "RMSE: 35927.247889668055\n",
    "R2: 0.8201073191954292\n",
    "\n",
    "    VALORES CON valor=63\n",
    "    feature_1\n",
    "MAE: 26105.609540740712\n",
    "MSE: 1266840578.3410313\n",
    "RMSE: 35592.70400434661\n",
    "R2: 0.828237097073263\n",
    "    VALORES CON valor=63\n",
    "    feature_2\n",
    "MAE: 26093.385049955825\n",
    "MSE: 1266894552.180633\n",
    "RMSE: 35593.462211207174\n",
    "R2: 0.8282297791016645\n",
    "    diferencia\n",
    "f2-f1 (MAE) = -12\n",
    "f2-f1 (MSE) = 53.974 (elegimos feature 1)\n",
    "f2-f1 (RMSE) = 1\n",
    "f2-f1 (R2) = -0,000008\n",
    "\n",
    "(wrong!)    VALORES = 63 : otros\n",
    "    feature_1\n",
    "    select: surface_covered_in_m2\n",
    "MAE: 25885.978562020075\n",
    "MSE: 1286649928.941028\n",
    "RMSE: 35869.90282870903\n",
    "R2: 0.8255512724933425\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8257a620",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\n",
    "# mostrar la funcion\n",
    "y[y.index.intersection(pd.DataFrame(Dicto['data_cruda'][1]).index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99abe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcount    8998.0\n",
      "\tmean    156544.17\n",
      "\tstd    85552.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_descr(y):\n",
    "    str = ''\n",
    "    for i in range(1,4):\n",
    "        str += '\\t{}\\n'.format(((y.describe()[i-1:i]).round(2)).to_string())\n",
    "    return str\n",
    "\n",
    "print (print_descr(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0588bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector predict: price\n",
      "_________________________\n",
      "describe y_train \n",
      "\tcount    8998.0\n",
      "\tmean    156544.17\n",
      "\tstd    85552.11\n",
      "\n",
      "describe y_test \n",
      "\tcount    3000.0\n",
      "\tmean    160981.71\n",
      "\tstd    87739.51\n",
      "\n",
      "test_train_pct_count: 33.34 %\n"
     ]
    }
   ],
   "source": [
    "# Model['linreg'][0] - COMPROBACION DEL MODELO\n",
    "#\n",
    "print ('Vector predict: price\\n'+'_'*25)\n",
    "print ('describe y_train \\n{}'.format(print_descr(ytrain)))\n",
    "print ('describe y_test \\n{}'.format(print_descr(ytest)))\n",
    "\n",
    "\n",
    "print ('test_train_pct_count: {} %'.format(((ytest.describe()[0]/ytrain.describe()[0])*100).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fb2ae",
   "metadata": {},
   "source": [
    "----------------\n",
    "**OPTIMIZACION DEL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d87826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe de los scores obtenidos por cross validation\n",
      "_____________________________________________________\n",
      "\tcount    5.0\n",
      "\tmean    0.82\n",
      "\tstd    0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ESTANDARIZACION\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=90)\n",
    "\n",
    "score_cv = pd.Series(cross_val_score(linreg, Xtrain, ytrain, cv=k_fold))\n",
    "string = 'Describe de los scores obtenidos por cross validation\\n'+'_'*53\n",
    "print('{}\\n{}'.format(string, print_descr(score_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171ae40",
   "metadata": {},
   "source": [
    "    CONCLUIMOS QUE NUESTRO MODELO DE 49 PLACE_NAME's GENERALIZA EL VALOR CONTINUO DEL PRECIO PARA DEPARTAMENTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd440d",
   "metadata": {},
   "source": [
    "--------------------\n",
    "**EVALUACION VISUAL DEL MODELO CON DATOS DE OTRA MUESTRA PERO QUE SEAN REPRESENTATIVOS DE LA POBLACION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELDA TOTALMENTE SECUNDARIA\n",
    "## creamos la celda de \"verificacion de alternativas\"\n",
    "# para qué hago esto?? \n",
    "# agarro el dataset que vengo trabajando\n",
    "# le extraigo las columnas que fueron usadas en feature_1\n",
    "# y verifico las columnas que quedaron fuera del feature dentro del data original\n",
    "# Sigue...\n",
    "\n",
    "data_aux = pd.DataFrame(Dicto['data'][0]) # data_aux = data  (!) no estamos reestableciendo una instancia anterior\n",
    "display (data_aux)\n",
    "features_1\n",
    "lista = []\n",
    "for i in range(len(list(data_aux.columns))):\n",
    "    booleano = False\n",
    "    for j in range(len(features_1)):\n",
    "        elemento = features_1[j] in list(data_aux.columns)[i]\n",
    "        if elemento: \n",
    "            booleano = True            \n",
    "    lista.append(booleano)\n",
    "    \n",
    "not_features_1 = []\n",
    "for i in range(len(lista)):\n",
    "    if lista[i] == False:\n",
    "        not_features_1.append(list(data_aux.columns)[i])\n",
    "        \n",
    "data_aux = data_aux[not_features_1]\n",
    "data_aux.columns.name = 'data_aux'\n",
    "display (data_aux)\n",
    "\n",
    "\n",
    "print ('Se procede a actualizar data_pred')\n",
    "print ()\n",
    "print ('en data: Se procede a eliminar la columna surface_covered_in_m2 porqué está representada por sup_descubierta_pct')\n",
    "print ()\n",
    "print ('en data: Se procede a eliminar above_median porque la preselección de features demostró tener mejor rendimiento la categoría above_mean')\n",
    "\n",
    "## ...Entonces, volvemos a levantar data_pred\n",
    "# conservar las columnas originales (excepto las obsoletas \"above_median\")\n",
    "# Actualizamos el set en el que vamos a ir añadiendole las predicciones que cada modelo devuelve (estamos considerando todo el set, no solo el de entrenamiento).\n",
    "\n",
    "data_pred = pd.DataFrame(Dicto['data_pred'][0])\n",
    "data_pred = data_pred.drop('above_median', axis=1)\n",
    "Dicto['data_pred'] = data_pred.to_dict(), data_info(data_pred, 'data_pred')\n",
    "\n",
    "\n",
    "## por ultimo verifico data y guardo\n",
    "\n",
    "data.drop(['above_median', 'surface_covered_in_m2'], axis=1, inplace=True)\n",
    "Dicto['data'] = data.to_dict(), data_info(data).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b072e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea una prediccion de un data_aux de data para que la serie sea del tamaño de la muetra\n",
    "data_aux = pd.concat([data[features_1],dummy_place], axis=1)\n",
    "array_predict = linreg.predict(data_aux) \n",
    "\n",
    "data = pd.DataFrame(Dicto['data_pred'][0]) #CARGA DATASET\n",
    "data['y_pred'] = array_predict #MODIFICACION DATASET\n",
    "display (data) #MUESTRA DATASET\n",
    "Dicto['data_pred'] = data.to_dict(), data_info(data).to_dict() #GUARDA DATASET\n",
    "data = pd.DataFrame(Dicto['data'][0]) #CARGA DATASET"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b82710a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "5ee97303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "x='surface_total_in_m2'\n",
    "y_1='price'\n",
    "y_2='y_pred'\n",
    "\n",
    "\n",
    "x1 = data[x]\n",
    "x2 = data[x]\n",
    "y_real = data[y_1]\n",
    "y_pred = data[y_2]\n",
    "\n",
    "\n",
    "plt.scatter(x1, y_real)\n",
    "plt.scatter(x2, y_pred)\n",
    "plt.suptitle('y, y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "data_pred = pd.DataFrame(Dicto['data_pred'][0])\n",
    "visualizacion_dos_scatter(data, data_pred, 'surface_total_in_m2', 'price', 'y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excepcion en llave\n",
    "Dicto['models']\n",
    "Dicto.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737099e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicture['linreg'][0] # X de linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12c2de",
   "metadata": {},
   "source": [
    "--------------------\n",
    "**EXPLORACION DE LA MUESTRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 18\n",
    "serie_same = pd.Series(Dicto['dummy_place'][1])\n",
    "serie_same;\n",
    "\n",
    "serie_filter = pd.DataFrame(Dicto['data'][0])\n",
    "serie_filter = serie_filter.place_name.unique()\n",
    "serie_filter;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 19\n",
    "muestra = pd.read_csv('muestra_currency_nan.csv')\n",
    "muestra = muestra.drop(list(muestra.columns)[0], axis=1)\n",
    "mask_1 = muestra.property_type == 'apartment'\n",
    "mask_2 = muestra.place_name.isin(serie_same) # 2193 - 1959 = 230: muestras más, si en vez de usar serie_same, usamos serie filter, (obtenemos una muesrta más grande, y después hay que matchiar los otros con los otros) no vale\n",
    "\n",
    "# Muestra_pred\n",
    "muestra = muestra[mask_1 & mask_2]\n",
    "display(muestra)\n",
    "Dicto['muestra'] = muestra.to_dict(), data_info(muestra,'muestra').to_dict()\n",
    "Dicto['muestra_pred'] = muestra.to_dict(), data_info(muestra,'muestra').to_dict()\n",
    "\n",
    "\n",
    "## Muestra\n",
    "muestra = variables_feature(muestra)\n",
    "Dicto['muestra'] = muestra.to_dict(), data_info(muestra,'muestra').to_dict()\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CONSERVANDO LAS DIMENSIONES EN TODAS LAS MUESTRAS\n",
    "\n",
    "display (data_info(muestra,'muestra'))\n",
    "analisis_nans(muestra.loc[:,['surface_total_in_m2', 'surface_covered_in_m2','place_name']])\n",
    "print ()\n",
    "print ('Accion a tomar: limpiar en funcion de los nans de \"sup_descubierta_pct\"')\n",
    "\n",
    "muestra = muestra.loc[muestra.sup_descubierta_pct.notna()]\n",
    "muestra = muestra.drop('surface_covered_in_m2', axis=1)\n",
    "lista_filter = muestra.index\n",
    "\n",
    "Dicto['muestra'] = muestra.to_dict(), data_info(muestra,'muestra').to_dict() # GUARDO MUESTRA\n",
    "\n",
    "muestra = pd.DataFrame(Dicto['muestra_pred'][0]) # CARGO OTRA MUESRTA\n",
    "muestra = muestra.filter(lista_filter, axis = 0) # MODIFICO OTRA MUESRTA\n",
    "Dicto['muestra_pred'] = muestra.to_dict(), data_info(muestra,'muestra').to_dict() # GUARDO OTRA MUESRTA\n",
    "\n",
    "muestra = pd.DataFrame(Dicto['muestra'][0]) # CARGO MUESTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c110d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 21\n",
    "data_check = pd.read_csv('data_apartment_4_statistic.csv')\n",
    "data_check = data_check.rename({'Unnamed: 0':'place_name'}, axis=1)\n",
    "data_check.set_index('place_name', inplace=True)\n",
    "\n",
    "apartment_mean = data_check['apartment_mean_surface_total_in_m2'].dropna()\n",
    "lista_place_name = apartment_mean.index\n",
    "lista_apartment_mean = apartment_mean.values\n",
    "\n",
    "for i, elemento in enumerate(lista_place_name):\n",
    "    #display(np.array((muestra.loc[mascara_iter_1 & (muestra.place_name == elemento), 'surface_total_in_m2']) >= lista_apartment_mean[i]).astype(int)) # columna dummy\n",
    "    muestra.loc[(muestra.place_name == elemento), 'above_mean'] = np.array((muestra.loc[(muestra.place_name == elemento), 'surface_total_in_m2']) >= lista_apartment_mean[i]).astype(int)\n",
    "    \n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dummy de la muestra, reacondicionamiento\n",
    "dummy_place_sample = pd.get_dummies(muestra.place_name)\n",
    "\n",
    "lista_dummy_original = serie_same.values\n",
    "lista_dummy_muestra = dummy_place_sample.columns\n",
    "\n",
    "difference_1 = set(lista_dummy_original).difference(set(lista_dummy_muestra)) ##diference 1 es clave, son los valores que debo excluir del set de entrenamiento para mejorar la estimacion sobre la muestra\n",
    "difference_2 = set(lista_dummy_muestra).difference(set(lista_dummy_original))\n",
    "list_difference = list(difference_1.union(difference_2))\n",
    "print(list_difference)#https://www.delftstack.com/es/howto/python/difference-between-two-lists-python/\n",
    "\n",
    "dummy_place_sample.loc[:,difference_1] = 0\n",
    "dummy_place_sample.columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CHEQUEO DE NANS ENTRE INSTANCIAS DE MUESTRAS\n",
    "Visualizar = False\n",
    "\n",
    "if Visualizar:\n",
    "    df = data_info(muestra)\n",
    "    instancias = [pd.DataFrame(Dicto['muestra_pred'][1]), df]\n",
    "    labels = ['muestra_1', 'muestra actual']\n",
    "    sns.set()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(22,4))\n",
    "    fig.suptitle('PORCENTAJE NANS [%]')\n",
    "    fig.subplots_adjust(wspace = 0.4)\n",
    "\n",
    "    for i in range(len(instancias)):\n",
    "        df_i = instancias[i]\n",
    "        ax[i].barh(df_i.columna, df_i.pct_nan)\n",
    "        ax[i].set(xlim = (0,100), title='dataset: '+ labels[i])\n",
    "        ax[i].minorticks_on()\n",
    "        ax[i].grid(which='minor', axis='x', lw=1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3df11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá estuvimos manoseando muestra, y creamos X, acá aparece Dicture\n",
    "X = pd.concat([muestra[features_1], dummy_place_sample], axis=1)\n",
    "#podriamos predecir acá\n",
    "Dicture['muestra_1'] = X,0,0,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01597c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 25\n",
    "\n",
    "array_predict = linreg.predict(X)\n",
    "\n",
    "muestra_pred = pd.DataFrame(Dicto['muestra_pred'][0])\n",
    "muestra_pred['y_pred'] = array_predict\n",
    "Dicto['muestra_pred'] = muestra_pred.to_dict(), data_info(muestra_pred, 'muestra_pred').to_dict()\n",
    "\n",
    "\n",
    "a = 'muestra_1'\n",
    "Dicture[a] = Dicture[a][0], Dicture[a][1], Dicture[a][2], Dicture[a][3], array_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizacion_dos_scatter(data,muestra_pred, x='surface_total_in_m2', y_1='price', y_2='y_pred')\n",
    "# x: surface_total_in_m2\n",
    "# puntos azules: valores reales de departamentos\n",
    "# puntos naranjas: valores predicho sobre una muestra sin valores reales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8d82e",
   "metadata": {},
   "source": [
    "    Conclusion:\n",
    "        \n",
    "        - El modelo predice mal para valores grandes de departamentos.\n",
    "        - Se debe diferenciar por place_name para identificar los barrios en los que el modelo responde al patrón de precios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12699360",
   "metadata": {},
   "source": [
    "------------\n",
    "**COMPROBACION VISUAL DEL RANGO DE APLICACION DEL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca121900",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 27\n",
    "dataview_1 = data[['property_type','surface_total_in_m2']]\n",
    "dataview_1['place_name'] = place_name_2\n",
    "dataview_1['price'] = data.price\n",
    "\n",
    "dataview_1['id'] = 1\n",
    "\n",
    "dataview_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataview_2 = muestra_pred[['property_type', 'surface_total_in_m2', 'place_name', 'y_pred']]\n",
    "\n",
    "place_missing = set(place_name_2).difference(set(muestra_pred.place_name)) # eliminar de la muestra original\n",
    "\n",
    "dataview_2['id'] = 2\n",
    "\n",
    "dataview_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 29\n",
    "dataview_1 = dataview_1.drop(dataview_1[dataview_1.place_name.isin(list(place_missing))].index)\n",
    "#\n",
    "print ('Si eliminamos los elementos de place_missing de la muestra de entrenamiento, estaríamos entrenando ajustando a esta muestra de verificacion.')\n",
    "#\n",
    "dataview_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataview_2.rename({'y_pred': 'price'}, axis=1, inplace=True)\n",
    "dataview_1 = dataview_1.append(dataview_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a287e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 31 - A VER (!)\n",
    "#g = sns.FacetGrid(dataview_1, row = 'place_name', hue='id', sharex=False, sharey=False)\n",
    "#g.map(sns.scatterplot, 'surface_total_in_m2', 'price')\n",
    "#g.add_legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c223a78",
   "metadata": {},
   "source": [
    "###  Parte 2 - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e671c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fit_transform(X):\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    X.columns.name = 'fit_transform'\n",
    "    return display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b630e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fda16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Celda 36\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df = data_info(data)\n",
    "## data.loc[:,data.columns.isin(df[df['dtype'] == 'float64'].columna.values)] #check\n",
    "X = data.loc[:,data.columns.isin(df[df['dtype'] == 'float64'].columna.values)]\n",
    "X = X.drop(['price', 'above_mean', 'price_usd_per_m2'], axis=1)\n",
    "\n",
    "Dicture['model_ridge_cv'] = X,1,0,0,0\n",
    "\n",
    "\n",
    "\n",
    "y = data.price\n",
    "\n",
    "Dicture['model_ridge_cv'] = X,y,0,0,0\n",
    "\n",
    "\n",
    "check_fit_transform(X) #funcion creada\n",
    "\n",
    "\n",
    "X_std = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "\n",
    "Dicture['model_ridge_cv'] = X_std,y,0,0,0\n",
    "\n",
    "\n",
    "X_std.columns.name='X_std'\n",
    "display (X_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d058fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACA TENEMOS QUE ACTUALIZAR Dicto[models] pero vamos a esperar para hacerlo en 2 modelos al mismo tiempo\n",
    "\n",
    "# nueva convencion: si se crea un modelo y se fitea en otra variable se crea un string de la instanciacion con los hiperparámetros\n",
    "\n",
    "Dicture['model_ridge_cv'] = X_std,y,0,0,0, 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5032e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Division\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size = 0.3, random_state = 117)\n",
    "\n",
    "#1 y 2. Defino el modelo y los hiperparámetros - #creo un modelo que no lo entreno\n",
    "model_ridge_cv = linear_model.RidgeCV(alphas= [0.3, 0.5, 1.0, 1.1, 1.15, 1.17, 1.18, 1.19, 1.2, 1.21, 1.22, 1.3, 1.4, 1.5, 10.0], \n",
    "                                   fit_intercept=True, normalize=False, cv=10)\n",
    "\n",
    "#agregar #1 y 2 en string\n",
    "Dicture['model_ridge_cv'] = Dicture['model_ridge_cv'][0],Dicture['model_ridge_cv'][1], Dicture['model_ridge_cv'][2], Dicture['model_ridge_cv'][3],Dicture['model_ridge_cv'][3], 'model_ridge_cv = linear_model.RidgeCV(alphas= [0.3, 0.5, 1.0, 1.1, 1.15, 1.17, 1.18, 1.19, 1.2, 1.21, 1.22, 1.3, 1.4, 1.5, 10.0], fit_intercept=True, normalize=False, cv=10)'\n",
    "\n",
    "\n",
    "#5. Entreno el modelo\n",
    "model_fit_ridge_cv = model_ridge_cv.fit(X_train, y_train)\n",
    "Model['model_fit_ridge_cv'] = model_fit_ridge_cv, 0, 0\n",
    "\n",
    "array_predict = model_fit_ridge_cv.predict(X_train)\n",
    "Dicture['model_fit_ridge_cv'] = X_std, y, 1, 1, 1, 1, 'str'\n",
    "Dicture['model_fit_ridge_cv'] = X_std,y,pd.DataFrame({'B_0': {'model_fit_ridge_cv':model_fit_ridge_cv.intercept_}}), model_fit_ridge_cv.coef_, array_predict, model_fit_ridge_cv.alpha_, str(model_fit_ridge_cv.best_score_)\n",
    "\n",
    "Model['model_fit_ridge_cv'] = Model['model_fit_ridge_cv'][0], Dicture['model_fit_ridge_cv'], Model['model_fit_ridge_cv'][2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a16a9140",
   "metadata": {},
   "source": [
    "## posibilidad de automatización de la útlima linea\n",
    "\n",
    "frame = Model['model_fit_ridge_cv']\n",
    "posicion = 1\n",
    "reemplazo = Dicture['model_fit_ridge_cv']\n",
    "\n",
    "\n",
    "def reemplazo_elemento_tupla(frame, posicion, reemplazo):\n",
    "    for i,elemento in enumerate(frame):\n",
    "        if i == posicion:\n",
    "            frame[posicion] = reemplazo\n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parámetros del modelo entrenado, performance:\n",
    "\n",
    "print(f'alpha_: {\"%.2f\" % model_fit_ridge_cv.alpha_}')\n",
    "print(f'best_score_: {\"%.2f\" % model_fit_ridge_cv.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. elijo el modelo\n",
    "\n",
    "best_alpha = model_fit_ridge_cv.alpha_\n",
    "model_ridge = linear_model.Ridge(alpha = best_alpha, fit_intercept = True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicture['model_ridge'] = X_std, y, 0, 0, 0, 'model_ridge = linear_model.Ridge(alpha = best_alpha, fit_intercept = True, normalize = False)'\n",
    "\n",
    "Dicture['model_fit_ridge'] = X_std, y, 1 ,1, 1, 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. entreno\n",
    "model_fit_ridge = model_ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "Model['model_fit_ridge'] = model_fit_ridge, 1, 1\n",
    "array_predict = model_fit_ridge.predict(X_train)\n",
    "Dicture['model_fit_ridge'] = Dicture['model_fit_ridge'][0],Dicture['model_fit_ridge'][1], pd.DataFrame({'B_0':{'model_fit_ridge':model_fit_ridge.intercept_}}), model_fit_ridge.coef_, array_predict, str(model_fit_ridge.score(X_train, y_train))\n",
    "\n",
    "# Exposicion de modelo:\n",
    "print(model_fit_ridge.coef_)\n",
    "print(model_fit_ridge.intercept_)\n",
    "print(model_fit_ridge.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509781bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVALUACION DE LA PERFOMANCE DEL MODELO CON RIDGE\n",
    "model_fit_ridge.score(X_test, y_test)\n",
    "\n",
    "# Conclusion: expresar la formula y verificar por coeficientes que sean iguales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de436a3",
   "metadata": {},
   "source": [
    "------------------\n",
    "Actualizacion de Dicto\n",
    "--------------\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183f25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3edde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## crear funcion en base a la celda de abajo\n",
    "\n",
    "def actualizar_Dicto_models():\n",
    "    difference_3 = set(Model.keys()).difference(set(Dicto['models'].index))\n",
    "    print (difference_3)\n",
    "    \n",
    "    for indice in difference_3:\n",
    "        \n",
    "        try:\n",
    "            if Dicture[indice][3] == 0: \n",
    "                etiqueta = '\\n\\tINTERCEPTO NO DEFINIDO EN \"{}\"\\n'.format(indice)\n",
    "                print ('='*80+etiqueta+'='*80)            \n",
    "                pass\n",
    "            if Dicture[indice][3] == 1:\n",
    "                etiqueta = '\\n\\tNO ESTA DEFINIDO EL INTERCEPTO EN \"{}\"\\n'.format(indice)\n",
    "                print ('='*40+etiqueta+'='*40)\n",
    "                pass\n",
    "        except:\n",
    "            frame = dict(zip(list(Dicture[indice][0].columns) , list(Dicture[indice][3])))    # el list es importante para borrar el name a la column\n",
    "            frame = pd.DataFrame({indice: pd.Series(frame)}).T\n",
    "            frame = (Dicture[indice][2]).join(frame)\n",
    "            Dicto['models'] = Dicto['models'].append(frame)\n",
    "        \n",
    "\"\"\"\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "~\\AppData\\Local\\Temp/ipykernel_2120/3502676010.py in <module>\n",
    "      1 display (Dicto['models'])\n",
    "----> 2 actualizar_Dicto_models()\n",
    "      3 display (Dicto['models'])\n",
    "\n",
    "~\\AppData\\Local\\Temp/ipykernel_2120/257676095.py in actualizar_Dicto_models()\n",
    "      6 \n",
    "      7     for indice in difference_3:\n",
    "----> 8         frame = dict(zip(list(Dicture[indice][0].columns) , list(Dicture[indice][3])))    # el list es importante para borrar el name a la column\n",
    "      9         frame = pd.DataFrame({indice: pd.Series(frame)}).T\n",
    "     10         frame = (Dicture[indice][2]).join(frame)\n",
    "\n",
    "AttributeError: 'numpy.ndarray' object has no attribute 'columns'\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "~\\AppData\\Local\\Temp/ipykernel_8652/3502676010.py in <module>\n",
    "      1 display (Dicto['models'])\n",
    "----> 2 actualizar_Dicto_models()\n",
    "      3 display (Dicto['models'])\n",
    "\n",
    "~\\AppData\\Local\\Temp/ipykernel_8652/2550046604.py in actualizar_Dicto_models()\n",
    "      6 \n",
    "      7     for indice in difference_3:\n",
    "----> 8         frame = dict(zip(list(Dicture[indice][0].columns) , list(Dicture[indice][3])))    # el list es importante para borrar el name a la column\n",
    "      9         frame = pd.DataFrame({indice: pd.Series(frame)}).T\n",
    "     10         frame = (Dicture[indice][2]).join(frame)\n",
    "\n",
    "TypeError: 'int' object is not iterable\n",
    "    \n",
    "    \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c407d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_3 = set(Model.keys()).difference(set(Dicto['models'].index))\n",
    "print (difference_3)\n",
    "\n",
    "for indice in difference_3:\n",
    "\n",
    "    Dicture[indice][2]# + pd.DataFrame(Dicture['model_fit_ridge_cv'][3])\n",
    "\n",
    "    frame = dict(zip(list(Dicture[indice][0].columns) , list(Dicture[indice][3])))    # el list es importante para borrar el name a la column\n",
    "\n",
    "    frame = pd.DataFrame({indice: pd.Series(frame)}).T\n",
    "\n",
    "    frame = (Dicture[indice][2]).join(frame)\n",
    "    \n",
    "    display (frame)\n",
    "    Dicto['models'] = Dicto['models'].append(frame)\n",
    "    \n",
    "Dicto['models']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7581fa",
   "metadata": {},
   "source": [
    "<u>**Evaluacion del modelo sobre la muestra**<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b819a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_info(muestra,'muestra')\n",
    "columnas_float = df.loc[(df['dtype'] == 'float64'), 'columna'].values\n",
    "\n",
    "muestra = muestra.loc[:,columnas_float].dropna(axis=1)\n",
    "\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b560b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya sabemos que normalizar no admite dummys\n",
    "Dicto['muestra'] = muestra.to_dict(), data_info(muestra,'muestra')\n",
    "muestra.drop('above_mean', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_fit_transform(muestra)\n",
    "X = scaler.fit_transform(muestra)\n",
    "Dicture['muestra_2'] = X,0,0,0,1,'y_pred_muestra_currency_nan' # el 1 porque me interesa ese valor son 3 dataset y 2 array, y 1 string\n",
    "\n",
    "muestra = pd.DataFrame(Dicto['muestra_pred'][0])\n",
    "array_predict = model_fit_ridge.predict(X)\n",
    "muestra['y_pred_ridge'] = array_predict\n",
    "Dicto['muestra_pred'] = muestra.to_dict(), data_info(muestra,'muestra_pred').to_dict()\n",
    "\n",
    "muestra = pd.DataFrame(Dicto['muestra'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13290024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "muestra"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd904d70",
   "metadata": {},
   "source": [
    "data\n",
    "#Dicture['model_lasso_cv'][0]\n",
    "list(data.iloc[:,3:10].iloc[:,4:].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44536e8e",
   "metadata": {},
   "source": [
    "###  Parte 3 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbadbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS FOR LASSO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ASUMIENDO TODAS NUESRTAS VARIABLE NUMERICAS\n",
    "feature = ['surface_total_in_m2','sup_total_pow2','sup_descubierta_pct','above_mean']\n",
    "X = data[feature]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_std = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)# <------------------------- así se hace\n",
    "#X_std['above_mean'] = X['above_mean'] ## es raro que lasso acepte dummy estandarizada pero no con 0 y 1\n",
    "\n",
    "y = data.price\n",
    "\n",
    "\n",
    "Dicture['model_lasso_cv'] = X_std, y, 0,0,0, 'linear_model.LassoCV(alphas= [0.05, 0.06, 0.07, 0.08, 0.09, 0.95, 0.97, 0.1, 0.12, 0.15, 0.2, 0.3, 1.0, 10.0], fit_intercept=True, normalize=False, cv=10, max_iter=1e4)'\n",
    "Dicture['model_fit_lasso_cv'] = X_std, y, 0,0,0,'hiperparámetros: take_it'\n",
    "Dicture['model_lasso'] = X_std,y,0,0,0,'model_lasso = linear_model.Lasso(alpha = take_it, fit_intercept = True, normalize = False)'\n",
    "Dicture['model_fit_lasso'] = X_std,y,1,1,0,'performance'\n",
    "\n",
    "\n",
    "# (3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size = 0.3, random_state = 117)\n",
    "# (1), (2)\n",
    "model_lasso_cv = linear_model.LassoCV(alphas= [0.05, 0.06, 0.07, 0.08, 0.09, 0.95, 0.97, 0.1, 0.12, 0.15, 0.2, 0.3, 1.0, 10.0], \n",
    "                                   fit_intercept=True, normalize=False, cv=10, max_iter=1e4)\n",
    "# (5)\n",
    "model_fit_lasso_cv = model_lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "indice='model_fit_lasso_cv'\n",
    "Dicture['model_fit_lasso_cv'] = Dicture[indice][0], Dicture[indice][1], Dicture[indice][2], Dicture[indice][2], Dicture[indice][4], model_fit_lasso_cv.alpha_, str(model_fit_lasso_cv.score(X_train, y_train))\n",
    "Model[indice] = model_fit_lasso_cv, 1, Dicture[indice]\n",
    "\n",
    "print(Dicture['model_fit_lasso_cv'][5])\n",
    "print(Dicture['model_fit_lasso_cv'][6])\n",
    "\n",
    "# (1, 2)\n",
    "take_it = Dicture['model_fit_lasso_cv'][5] # model_fit_lasso_cv.alpha_\n",
    "model_lasso = linear_model.Lasso(alpha = take_it, fit_intercept = True, normalize = False)\n",
    "\n",
    "# (5)\n",
    "model_fit_lasso = model_lasso.fit(X_train, y_train)\n",
    "indice= 'model_fit_lasso'\n",
    "#array_predict = predecir modelo con X_train: no, entonces cero\n",
    "Dicture['model_fit_lasso'] = X_std,y, pd.DataFrame({'B_0': {indice:model_fit_lasso.intercept_}}), model_fit_lasso.coef_, 0, str(model_fit_lasso.score(X_test, y_test))\n",
    "\n",
    "Model[indice] = model_fit_lasso, 1, Dicture[indice]\n",
    "\n",
    "print(model_fit_lasso.coef_)\n",
    "print(model_fit_lasso.intercept_)\n",
    "print(model_fit_lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0db437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5a9f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Dicture['model_fit_lasso_cv'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91220f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (Dicto['models'])\n",
    "actualizar_Dicto_models()\n",
    "display (Dicto['models'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3ce5e",
   "metadata": {},
   "source": [
    "<u>**APLICO EL MODELO A LA MUESTRA**<U>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "955dd875",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "borrar esto\n",
    "\n",
    "\n",
    "lista_pred = lista_featurend(muestra, 'y_pred_ridge')\n",
    "serie_pred_muestra = muestra.loc[:,lista_pred]\n",
    "\n",
    "lista_drop = lista_pred + ['surface_covered_in_m2']\n",
    "muestra.drop(lista_drop,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicture['model_fit_lasso'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a54890",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = pd.DataFrame(scaler.fit_transform(muestra), columns=muestra.columns)\n",
    "Dicture['muestra_3'] = X_std,0,0,0,1,'prediccion lasso sobre muestra currency_nan'\n",
    "\n",
    "array_predict = model_fit_lasso.predict(X_std)\n",
    "Dicture['muestra_3'] = X_std,0,0,0,array_predict,'prediccion lasso sobre muestra currency_nan'\n",
    "\n",
    "muestra_pred = pd.DataFrame(Dicto['muestra_pred'][0])\n",
    "muestra_pred['y_pred_lasso'] = array_predict\n",
    "\n",
    "Dicto['muestra_pred'] = muestra_pred.to_dict(), data_info(muestra_pred, 'muestra_pred').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19459780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01439b0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_aux = Dicture['linreg'][0]\n",
    "\n",
    "data_aux\n",
    "x = data_aux.surface_total_in_m2\n",
    "x\n",
    "y = Dicture['linreg'][4]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b42c",
   "metadata": {},
   "source": [
    "###  COMPROBACION VISUAL DE LOS MODELOS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e6987",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,8))\n",
    "\n",
    "\n",
    "### error en dicture: la y_pred de entrnamiento no es del same len que el X del [0]\n",
    "#data_aux = Dicture['linreg'][0]\n",
    "#x = data_aux.surface_total_in_m2\n",
    "#y = Dicture['linreg'][4]\n",
    "#plt.scatter(x,y, label='modelo entrenamiento')\n",
    "\n",
    "\n",
    "x = muestra.surface_total_in_m2\n",
    "y = muestra_pred.y_pred\n",
    "plt.scatter(x,y, label='modelo original')\n",
    "y = muestra_pred.y_pred_ridge\n",
    "plt.scatter(x, y, label='modelo_ridge')\n",
    "y = muestra_pred.y_pred_lasso\n",
    "plt.scatter(x, y, label='modelo_Lasso')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f4deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09edd966",
   "metadata": {},
   "source": [
    "### MODELO ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d959d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECESITO SOLO LOS COEFICIENTES DE LOS LUGARES Y LOS COEFICIENTES SON: SUPERFICIE_TOTAL, SUPERFICIE_POW2, SUP_DESCU_PCT, ABOVE_MEAN\n",
    "feature_cols = list(pd.DataFrame(Dicto['dummy_place'][0]).columns)\n",
    "lista_coeficientes = list(linreg.coef_)\n",
    "lista_coeficientes_dummy_place = lista_coeficientes[4:] #las primera 4 columnas son de otra cosa\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(25,10))\n",
    "barras=ax.barh(feature_cols, lista_coeficientes_dummy_place, color='red')\n",
    "#ax.axhline(0, color='black',linewidth=1)\n",
    "ax.set_ylabel('Coeficientes del modelo lineal')\n",
    "plt.xticks(rotation=30);\n",
    "plt.title('Coeficientes de regresion asociado a place_name')\n",
    "\n",
    "for i,barra in enumerate(barras):\n",
    "    x=barra.get_y()\n",
    "    y=barra.get_height()\n",
    "    ancho=barra.get_width()\n",
    "    if y>0:\n",
    "        plt.text(x+ancho,y+x,str(round(ancho))+' '+feature_cols[i],fontsize=14,color='black',ha='center',size=14)\n",
    "    #else:\n",
    "    #    plt.text(x+ancho/2,y-10,round(y,2),fontsize=14,color='black',ha='center',size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc1b66",
   "metadata": {},
   "source": [
    "#################################################################################################\n",
    "# Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239dfe7",
   "metadata": {},
   "source": [
    "vamos a partir de algunas premisas:\n",
    "\n",
    "1. La mejor generalización la hizo en \"La Plata\", y que existe la posibilidad de extraer la muestra completa del dataset (deptos)\n",
    "\n",
    "2. Voy a armar una matriz de correlación y me voy a quedar con todos los place_name que correlaciones con la Plata mas de 55\n",
    "\n",
    "*4. Voy a eliminar los place_missing de la muestra de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicto.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(Dicto['data'][0])\n",
    "la_plata = data[data.place_name == 'La Plata']\n",
    "la_plata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_plata.sort_values(by='surface_total_in_m2', ascending=True, inplace=True)\n",
    "la_plata['surface_pct_change'] = la_plata.surface_total_in_m2.pct_change()*100\n",
    "la_plata['price_pct_change'] = la_plata.price.pct_change()*100\n",
    "\n",
    "la_plata.reset_index(drop=True,inplace=True)\n",
    "la_plata['price_pct_change_positive'] = la_plata.eval('price_pct_change > 0')\n",
    "la_plata['changing_surface'] = la_plata.eval('surface_pct_change > 0.2 and surface_pct_change < 4')\n",
    "la_plata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea45d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = la_plata.above_mean == 0\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(la_plata[mask].surface_pct_change, '*')\n",
    "plt.plot(la_plata[~mask].surface_pct_change, '*')\n",
    "plt.suptitle('VARIACION DE LA SUPERFICIE')\n",
    "plt.ylabel('cambio porcentual %')\n",
    "plt.xlabel('indice superficies crecientes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee258fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = la_plata.above_mean == 0\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(la_plata[mask].surface_pct_change, '*')\n",
    "plt.plot(la_plata[~mask].surface_pct_change, '*')\n",
    "plt.plot(la_plata[mask].price_pct_change, 's')\n",
    "plt.plot(la_plata[~mask].price_pct_change, 's')\n",
    "plt.suptitle('VARIACION DE LA SUPERFICIE Y DEL PRECIO')\n",
    "plt.ylabel('cambio porcentual %')\n",
    "plt.xlabel('indice crecientes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "g = sns.scatterplot(x='surface_pct_change', y='price_pct_change', data=la_plata, hue='changing_surface')\n",
    "#g.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba594ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "g = sns.scatterplot(x='surface_total_in_m2', y='price_usd_per_m2', data=la_plata, hue='above_mean')\n",
    "#g.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.suptitle('DISPERSION: superficie vs precio')\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(20,90), ylim=(25000,200000))\n",
    "g = sns.scatterplot(x='surface_total_in_m2', y='price', data=la_plata, hue='price_pct_change_positive', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.suptitle('DISPERSION: superficie vs precio')\n",
    "ax = plt.axes()\n",
    "\n",
    "la_plata['surface2'] = la_plata.surface_total_in_m2*10000\n",
    "la_plata['price2'] = la_plata.price*4\n",
    "#ax.set(xlim=(20,90), ylim=(25000,200000))\n",
    "g = sns.scatterplot(x='surface2', y='price2', data=la_plata, hue='price_pct_change_positive', s=100)\n",
    "\n",
    "g.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.suptitle('DISPERSION: superficie vs precio')\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xscale='log', yscale='log')\n",
    "g = sns.scatterplot(x='surface_total_in_m2', y='price', data=la_plata, hue='price_pct_change_positive', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb39c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenes que volver a entrenar el modelo, 1 quitando los place_missing, y dos solo con las columnas rojas del sector izquierdo, buscalo dentro de una iteracion de los coeficientes! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
